defaults:
  - CLIPVisionModelPool@: _template
  - /dataset/image_classification/train@train_datasets: caltech101
  - /dataset/image_classification/test@test_datasets: caltech101
  - /model/clip-vit@models:
      - clip-vit-base-patch16_caltech101

# models:
#   _pretrained_:
#     _target_: transformers.CLIPVisionModel.from_pretrained
#     pretrained_model_name_or_path: ${...base_model}

processor:
  _target_: transformers.CLIPProcessor.from_pretrained
  pretrained_model_name_or_path: ${..base_model}

base_model: openai/clip-vit-base-patch16
